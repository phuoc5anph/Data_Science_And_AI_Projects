{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yFBX_-i-BFqm"},"outputs":[],"source":["import re\n","import numpy as np\n","import pickle\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14013,"status":"ok","timestamp":1717659170086,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"},"user_tz":-420},"id":"x_t0VBYgBCkj","outputId":"e091719f-c8b9-4e45-ae11-ad307ce8937a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unidecode\n","  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.8\n"]}],"source":["!pip install unidecode"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slzsZgj5BKbK","outputId":"091f9f6c-6349-4e5f-9f9d-48459ed1695b","executionInfo":{"status":"ok","timestamp":1717659199875,"user_tz":-420,"elapsed":29795,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Đường dẫn tới thư mục bạn muốn chuyển đến\n","path = '/content/drive/MyDrive/DACN3_Spell_VN/'\n","\n","# Thực hiện việc chuyển đến thư mục\n","os.chdir(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYYfo8guaKxH","executionInfo":{"status":"ok","timestamp":1717659200473,"user_tz":-420,"elapsed":603,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"f650c401-ff5f-4447-ade6-427bcc80d8fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["model_spell_ngram_4.h5\tspell_0.9897.h5  spell_0.99.h5\n","model_spell_ngram_5.h5\tspell_0.9899.h5  spell_ngram_5.h5\n"]}],"source":["!ls model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EMrxCzWA-JK"},"outputs":[],"source":["from collections import Counter\n","from keras.models import load_model\n","from nltk.tokenize import word_tokenize\n","from nltk import ngrams, word_tokenize\n","import numpy as np\n","import re\n","import unidecode\n","import string\n","from tqdm import tqdm\n","\n","import sys\n","\n","if not sys.warnoptions:\n","    import warnings\n","\n","    warnings.simplefilter(\"ignore\")\n","\n","model = load_model(\"model/model_spell_ngram_4.h5\")\n","\n","NGRAM = 4\n","MAXLEN = 32\n","alphabet = ['\\x00', ' ', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r',\n","            's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n","            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7',\n","            '8', '9', 'á', 'à', 'ả', 'ã', 'ạ', 'â', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ă', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ', 'ó', 'ò',\n","            'ỏ', 'õ', 'ọ', 'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ơ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'é', 'è', 'ẻ', 'ẽ', 'ẹ', 'ê',\n","            'ế', 'ề', 'ể', 'ễ', 'ệ', 'ú', 'ù', 'ủ', 'ũ', 'ụ', 'ư', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'í', 'ì', 'ỉ', 'ĩ', 'ị',\n","            'ý', 'ỳ', 'ỷ', 'ỹ', 'ỵ', 'đ', 'Á', 'À', 'Ả', 'Ã', 'Ạ', 'Â', 'Ấ', 'Ầ', 'Ẩ', 'Ẫ', 'Ậ', 'Ă', 'Ắ', 'Ằ', 'Ẳ',\n","            'Ẵ', 'Ặ', 'Ó', 'Ò', 'Ỏ', 'Õ', 'Ọ', 'Ô', 'Ố', 'Ồ', 'Ổ', 'Ỗ', 'Ộ', 'Ơ', 'Ớ', 'Ờ', 'Ở', 'Ỡ', 'Ợ', 'É', 'È',\n","            'Ẻ', 'Ẽ', 'Ẹ', 'Ê', 'Ế', 'Ề', 'Ể', 'Ễ', 'Ệ', 'Ú', 'Ù', 'Ủ', 'Ũ', 'Ụ', 'Ư', 'Ứ', 'Ừ', 'Ử', 'Ữ', 'Ự', 'Í',\n","            'Ì', 'Ỉ', 'Ĩ', 'Ị', 'Ý', 'Ỳ', 'Ỷ', 'Ỹ', 'Ỵ', 'Đ']\n","letters = list(\n","    \"abcdefghijklmnopqrstuvwxyzáàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđABCDEFGHIJKLMNOPQRSTUVWXYZÁÀẢÃẠÂẤẦẨẪẬĂẮẰẲẴẶÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÉÈẺẼẸÊẾỀỂỄỆÚÙỦŨỤƯỨỪỬỮỰÍÌỈĨỊÝỲỶỸỴĐ\")\n","accepted_char = list((string.digits + ''.join(letters)))\n","\n","\n","def extract_phrases(text):\n","    pattern = r'\\w[\\w ]*\\w|\\s\\W+|\\W+|\\n' #\\w[\\w ]*\\w|\\W+\n","    return re.findall(pattern, text)\n","\n","\n","def encoder_data(text, maxlen=MAXLEN):\n","    text = \"\\x00\" + text\n","    x = np.zeros((maxlen, len(alphabet)))\n","    for i, c in enumerate(text[:maxlen]):\n","        x[i, alphabet.index(c)] = 1\n","    if i < maxlen - 1:\n","        for j in range(i + 1, maxlen):\n","            x[j, 0] = 1\n","    return x\n","\n","\n","def decoder_data(x):\n","    x = x.argmax(axis=-1)\n","    return ''.join(alphabet[i] for i in x)\n","\n","\n","def nltk_ngrams(words, n=5):\n","    return ngrams(words.split(), n)\n","\n","\n","def guess(ngram):\n","    # Example: ngram = ('Tôi', 'ddi', 'học', 'ở', 'đâu')\n","    text = ' '.join(ngram)\n","    preds = model.predict(np.array([encoder_data(text)]), verbose=0)\n","    return decoder_data(preds[0]).strip('\\x00')\n","\n","#4.2 Hàm sử dụng mô hình ngram và các phương pháp xử lý ngôn ngữ tự nhiên để sửa lỗi chính tả cho một cụm từ\n","def correct(sentence):\n","    # Lặp qua từng ký tự trong câu.\n","    for i in sentence:\n","        # Kiểm tra xem ký tự hiện tại có trong danh sách các ký tự được chấp nhận hay không.\n","        # Nếu không, thay thế ký tự đó bằng khoảng trắng.\n","        if i not in accepted_char:\n","            sentence = sentence.replace(i, \" \")\n","\n","    # Kiểm tra số từ trong câu\n","    num_words = len(sentence.split())\n","    # Nếu số từ không đủ để tạo n-gram, trả về câu không đổi\n","    if num_words < NGRAM:\n","      ngrams = list(nltk_ngrams(sentence, n=num_words))\n","      # Đoán các từ trong các n-gram.\n","      guessed_ngrams = list(guess(ngram) for ngram in ngrams)\n","      # Tạo một danh sách các bảng ứng viên từ.\n","      candidates = [Counter() for _ in range(len(guessed_ngrams) + num_words - 1)]\n","      candidates_len = len(candidates)\n","      # Lặp qua các n-gram đã đoán.\n","      for nid, ngram in (enumerate(guessed_ngrams)):\n","          # Tách các từ từ n-gram.\n","          for wid, word in (enumerate(re.split(' +', ngram))):\n","              # Cập nhật bảng ứng viên từ với từ hiện tại.\n","              if (candidates_len>nid + wid):\n","                candidates[nid + wid].update([word])\n","      # Xây dựng câu đúng bằng cách chọn từ phổ biến nhất từ mỗi bảng ứng viên từ.\n","      #output = ' '.join(c.most_common(1)[0][0] for c in candidates)\n","      output = ' '.join(c.most_common(1)[0][0] if c else sentence.split()[index] for index, c in enumerate(candidates))\n","    else:\n","      # Tạo các n-gram từ câu đã được xử lý.\n","      ngrams = list(nltk_ngrams(sentence, n=NGRAM))\n","      # Đoán các từ trong các n-gram.\n","      guessed_ngrams = list(guess(ngram) for ngram in ngrams)\n","      # Tạo một danh sách các bảng ứng viên từ.\n","      candidates = [Counter() for _ in range(len(guessed_ngrams) + NGRAM - 1)]\n","      candidates_len = len(candidates)\n","      # Lặp qua các n-gram đã đoán.\n","      for nid, ngram in (enumerate(guessed_ngrams)):\n","          # Tách các từ từ n-gram.\n","          for wid, word in (enumerate(re.split(' +', ngram))):\n","              # Cập nhật bảng ứng viên từ với từ hiện tại.\n","              if (candidates_len>nid + wid):\n","                candidates[nid + wid].update([word])\n","      # Xây dựng câu đúng bằng cách chọn từ phổ biến nhất từ mỗi bảng ứng viên từ.\n","      #output = ' '.join(c.most_common(1)[0][0] for index, c in enumerate(candidates))\n","      output = ' '.join(c.most_common(1)[0][0] if c else sentence.split()[index] for index, c in enumerate(candidates))\n","\n","    return output\n","\n","def check_text(regex, text):\n","    pattern = re.compile(regex)\n","    if pattern.fullmatch(text):\n","        return True\n","    else:\n","        return False\n","\n","# 4.2 Hàm sử dụng mô hình ngram và các phương pháp xử lý ngôn ngữ tự nhiên để sửa lỗi chính tả cho một văn bản\n","def correct_2(text):\n","  ep = extract_phrases(text)\n","  rs_ = \"\"\n","  for value in ep:\n","    regex = r'\\w[\\w ]+'\n","    if check_text(regex, value):\n","      rs_ = rs_ + correct(value)\n","    else:\n","      rs_ = rs_ + value\n","  return rs_"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"lGHZFkAudtAA","executionInfo":{"status":"ok","timestamp":1717659215787,"user_tz":-420,"elapsed":3815,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"43140226-3b78-47f7-fd81-f3acab35f040"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Bất cứ lúc nao, trong cuộc phiêu lưu đơn thương độc mã. Tôi đi học ở đâu. Cơn mưa ngang qua,  cơn mưa  @ ngang qua\\nBất cứ lúc nao, trong cuộc phiêu lưu đơn thương độc mã. Tôi đi học ở đâu. Cơn mưa ngang qua,  cơn mưa  @ ngang qua'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["text= \"Bất cuws lúc nao, trong cuộc phieeu lưu đơn thương độc max. Tôi ddi học ở đaau. Cơn mưa ngang qua,  cơn muwa  @ ngang qua\\nBất cuws lúc nao, trong cuộc phieeu lưu đơn thương độc max. Tôi ddi học ở đaau. Cơn mưa ngang qua,  cơn muwa  @ ngang qua\"\n","results = correct_2(text)\n","results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EetAtBbers2t","executionInfo":{"status":"ok","timestamp":1717659222637,"user_tz":-420,"elapsed":6858,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"9f1660f4-118e-407f-f72a-2cca241c6e20"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded successfully!\n"]},{"output_type":"stream","name":"stderr","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}],"source":["import pickle\n","\n","# Đọc dữ liệu từ file\n","with open('data/my_data_test.pkl', 'rb') as file:\n","    loaded_data = pickle.load(file)\n","\n","print(\"Data loaded successfully!\")\n","print(loaded_data)"]},{"cell_type":"code","source":["len(loaded_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P_5SczcHgNDR","executionInfo":{"status":"ok","timestamp":1717659223804,"user_tz":-420,"elapsed":382,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"63b42a21-e3cf-44d7-aefd-664fa91e0449"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["274155"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"beFA19Sve2JC","executionInfo":{"status":"ok","timestamp":1717659223804,"user_tz":-420,"elapsed":8,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"7c2e01dd-e876-47ff-b772-e38505ef30ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["[' Mạo hiểm rừng Đa Mi Cuộc hành quân khám phá thác sương mù Ẩn mình trong cánh rừng Đa Mi (Hàm Thuận Bắc, Bình Thuận) bạt ngàn là hồ thủy điện Đa Mi đẹp như một nàng công chúa, ngọn thác sương mù hùng vĩ, cao ngất, uốn lượn như con rồng bạc khổng lồ', ' Mạo ihểm rừng Đa Mi Cuộc hành quân khá mphá thác sương mù Ẩn mình trong cánh rừng Đa Mi (Hàm Thuận Bắc, Bình Thuận) bạt ngàn là hồ thủy điện Đa Mi đẹp như một nàng công chúa, ngọn thác sương mù hùng vĩ, cao ngất, uốn qượn như con rồng bạc khổng lồ']\n"]}],"source":["test_data = loaded_data[0:2000]\n","print(test_data[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"t_vla46vhOYM","executionInfo":{"status":"ok","timestamp":1717659223804,"user_tz":-420,"elapsed":7,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"3f18f248-0763-4e56-c165-a99bf65e45aa"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'000 khách đến vịnh Nha Trang Theo trực ban bộ đội biên phòng tại cảng du lịch Cầu Đá (Vĩnh Nguyên), trong những ngày lễ vừa qua có hơn 16'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}],"source":["correct_2(\"000 khách đến vịnh Nha Trang Theo trực ban bộ đội biên phòng tại cảng du lịch Cầu Đá (Vĩnh Nguyên), trong những ngày lễ vừa qua có hơn 16\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"wJFkzECIwBRz","executionInfo":{"status":"ok","timestamp":1717659224805,"user_tz":-420,"elapsed":1006,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"9c4ea7ad-5965-476d-e3da-3500aa3dbe32"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Lễ té nước, người Thái gọi là Song Kian - tương tự Tết Nguyên đán của người Việt - bắt đầu từ ngày 12 đến 14-'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}],"source":["correct_2(\"Lễ té nước, người Thái ọgi la Song Kian - tương tự Tết Nguyên đán của người Việt - bắt đầu từ ngày 12 đến 14-\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WBKJXENifK_7","executionInfo":{"status":"ok","timestamp":1717661669695,"user_tz":-420,"elapsed":2444900,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"f65fd8e4-4c5b-46fe-eb21-3ec178d891fc"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 2000/2000 [40:44<00:00,  1.22s/it]\n"]}],"source":["from tqdm import tqdm\n","result_predict = []\n","result_predict_row_error = []\n","result_predict_real = []\n","for text in tqdm(test_data):\n","    # Kiểm tra nếu cụm từ không khớp với mẫu ký tự cho phép thì bỏ qua\n","    results = correct_2(text[1])\n","    result_predict.append(results)\n","    result_predict_real.append(text[0])\n","    if(results != text[0]):\n","      result_predict_row_error.append([text[0], results])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ean_HT8Du_vY","executionInfo":{"status":"ok","timestamp":1717661669697,"user_tz":-420,"elapsed":47,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"a8679536-4890-4506-8b7e-73eec0042e20"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["898"]},"metadata":{},"execution_count":13}],"source":["len(result_predict_row_error)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v6ae-EtWmmbS"},"outputs":[],"source":["import string\n","import unicodedata\n","import editdistance\n","\n","\n","def ocr_metrics(predicts, ground_truth, norm_accentuation=False, norm_punctuation=False):\n","    \"\"\"Calculate Character Error Rate (CER), Word Error Rate (WER) and Sequence Error Rate (SER)\"\"\"\n","\n","    if len(predicts) == 0 or len(ground_truth) == 0:\n","        return (1, 1, 1)\n","\n","    cer, wer, ser = [], [], []\n","\n","    for (pd, gt) in zip(predicts, ground_truth):\n","\n","        if norm_accentuation:\n","            pd = unicodedata.normalize(\"NFKD\", pd).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n","            gt = unicodedata.normalize(\"NFKD\", gt).encode(\"ASCII\", \"ignore\").decode(\"ASCII\")\n","\n","        if norm_punctuation:\n","            pd = pd.translate(str.maketrans(\"\", \"\", string.punctuation))\n","            gt = gt.translate(str.maketrans(\"\", \"\", string.punctuation))\n","\n","        pd_cer, gt_cer = list(pd.lower()), list(gt.lower())\n","        dist = editdistance.eval(pd_cer, gt_cer)\n","        cer.append(dist / (max(len(pd_cer), len(gt_cer))))\n","\n","        pd_wer, gt_wer = pd.lower().split(), gt.lower().split()\n","        dist = editdistance.eval(pd_wer, gt_wer)\n","        wer.append(dist / (max(len(pd_wer), len(gt_wer))))\n","\n","        pd_ser, gt_ser = [pd], [gt]\n","        dist = editdistance.eval(pd_ser, gt_ser)\n","        ser.append(dist / (max(len(pd_ser), len(gt_ser))))\n","\n","    cer_f = sum(cer) / len(cer)\n","    wer_f = sum(wer) / len(wer)\n","    ser_f = sum(ser) / len(ser)\n","\n","    return (cer_f, wer_f, ser_f)"]},{"cell_type":"code","source":["test_data_noise = []\n","for item in test_data:\n","  test_data_noise.append(item[1])"],"metadata":{"id":"c1ryeH5l2YdP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate = ocr_metrics(predicts=test_data_noise,\n","                                  ground_truth=result_predict_real,\n","                                  norm_accentuation=False,\n","                                  norm_punctuation=False)\n","\n","e_corpus = \"\\n\".join([\n","    \"Metrics:\",\n","    \"Character Error Rate: {}\".format(evaluate[0]),\n","    \"Word Error Rate:      {}\".format(evaluate[1]),\n","    \"Sequence Error Rate:  {}\".format(evaluate[2]),\n","])"],"metadata":{"id":"43piyNYl2Zx2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(e_corpus)"],"metadata":{"id":"b73mjYxc2bEn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1717661669701,"user_tz":-420,"elapsed":14,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"050d215a-068b-4ea4-f183-1b868743014f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Metrics:\n","Character Error Rate: 0.040929927754441243\n","Word Error Rate:      0.11968599781415802\n","Sequence Error Rate:  0.8625\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bud0jMOMmocW"},"outputs":[],"source":["evaluate = ocr_metrics(predicts=result_predict,\n","                                  ground_truth=result_predict_real,\n","                                  norm_accentuation=False,\n","                                  norm_punctuation=False)\n","\n","e_corpus = \"\\n\".join([\n","    \"Metrics:\",\n","    \"Character Error Rate: {}\".format(evaluate[0]),\n","    \"Word Error Rate:      {}\".format(evaluate[1]),\n","    \"Sequence Error Rate:  {}\".format(evaluate[2]),\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASvu45n2mpcC","executionInfo":{"status":"ok","timestamp":1717661670333,"user_tz":-420,"elapsed":15,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"b7b7ce6d-f98c-47f8-b5b2-59685f6088fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Metrics:\n","Character Error Rate: 0.009038160576172863\n","Word Error Rate:      0.031506265330400324\n","Sequence Error Rate:  0.449\n"]}],"source":["print(e_corpus)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
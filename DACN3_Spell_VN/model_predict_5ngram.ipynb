{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import re\n","import numpy as np\n","import pickle\n","import os"],"metadata":{"id":"yFBX_-i-BFqm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install unidecode"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_t0VBYgBCkj","executionInfo":{"status":"ok","timestamp":1717507963657,"user_tz":-420,"elapsed":23811,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"82b36e7a-ffa7-44a0-9945-e252559d2b5f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting unidecode\n","  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: unidecode\n","Successfully installed unidecode-1.3.8\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Đường dẫn tới thư mục bạn muốn chuyển đến\n","path = '/content/drive/MyDrive/DACN3_Spell_VN/'\n","\n","# Thực hiện việc chuyển đến thư mục\n","os.chdir(path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slzsZgj5BKbK","executionInfo":{"status":"ok","timestamp":1717508024552,"user_tz":-420,"elapsed":60899,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"15a0c9c8-7ba3-4661-848d-3b16c92b2868"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYYfo8guaKxH","executionInfo":{"status":"ok","timestamp":1717508025265,"user_tz":-420,"elapsed":719,"user":{"displayName":"phước lê văn","userId":"03208554203373582553"}},"outputId":"6d12dafc-caee-492d-926b-02f0460e545a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["model_spell_ngram_4.h5\tspell_0.9897.h5  spell_0.99.h5\n","model_spell_ngram_5.h5\tspell_0.9899.h5  spell_ngram_5.h5\n"]}]},{"cell_type":"code","source":["from collections import Counter\n","from keras.models import load_model\n","from nltk.tokenize import word_tokenize\n","from nltk import ngrams, word_tokenize\n","import numpy as np\n","import re\n","import unidecode\n","import string\n","from tqdm import tqdm\n","\n","import sys\n","\n","if not sys.warnoptions:\n","    import warnings\n","\n","    warnings.simplefilter(\"ignore\")\n","\n","model = load_model(\"model/model_spell_ngram_5.h5\")\n","\n","NGRAM = 5\n","MAXLEN = 40\n","alphabet = ['\\x00', ' ', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r',\n","            's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n","            'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7',\n","            '8', '9', 'á', 'à', 'ả', 'ã', 'ạ', 'â', 'ấ', 'ầ', 'ẩ', 'ẫ', 'ậ', 'ă', 'ắ', 'ằ', 'ẳ', 'ẵ', 'ặ', 'ó', 'ò',\n","            'ỏ', 'õ', 'ọ', 'ô', 'ố', 'ồ', 'ổ', 'ỗ', 'ộ', 'ơ', 'ớ', 'ờ', 'ở', 'ỡ', 'ợ', 'é', 'è', 'ẻ', 'ẽ', 'ẹ', 'ê',\n","            'ế', 'ề', 'ể', 'ễ', 'ệ', 'ú', 'ù', 'ủ', 'ũ', 'ụ', 'ư', 'ứ', 'ừ', 'ử', 'ữ', 'ự', 'í', 'ì', 'ỉ', 'ĩ', 'ị',\n","            'ý', 'ỳ', 'ỷ', 'ỹ', 'ỵ', 'đ', 'Á', 'À', 'Ả', 'Ã', 'Ạ', 'Â', 'Ấ', 'Ầ', 'Ẩ', 'Ẫ', 'Ậ', 'Ă', 'Ắ', 'Ằ', 'Ẳ',\n","            'Ẵ', 'Ặ', 'Ó', 'Ò', 'Ỏ', 'Õ', 'Ọ', 'Ô', 'Ố', 'Ồ', 'Ổ', 'Ỗ', 'Ộ', 'Ơ', 'Ớ', 'Ờ', 'Ở', 'Ỡ', 'Ợ', 'É', 'È',\n","            'Ẻ', 'Ẽ', 'Ẹ', 'Ê', 'Ế', 'Ề', 'Ể', 'Ễ', 'Ệ', 'Ú', 'Ù', 'Ủ', 'Ũ', 'Ụ', 'Ư', 'Ứ', 'Ừ', 'Ử', 'Ữ', 'Ự', 'Í',\n","            'Ì', 'Ỉ', 'Ĩ', 'Ị', 'Ý', 'Ỳ', 'Ỷ', 'Ỹ', 'Ỵ', 'Đ']\n","letters = list(\n","    \"abcdefghijklmnopqrstuvwxyzáàảãạâấầẩẫậăắằẳẵặóòỏõọôốồổỗộơớờởỡợéèẻẽẹêếềểễệúùủũụưứừửữựíìỉĩịýỳỷỹỵđABCDEFGHIJKLMNOPQRSTUVWXYZÁÀẢÃẠÂẤẦẨẪẬĂẮẰẲẴẶÓÒỎÕỌÔỐỒỔỖỘƠỚỜỞỠỢÉÈẺẼẸÊẾỀỂỄỆÚÙỦŨỤƯỨỪỬỮỰÍÌỈĨỊÝỲỶỸỴĐ\")\n","accepted_char = list((string.digits + ''.join(letters)))\n","\n","\n","def extract_phrases(text):\n","    pattern = r'\\w[\\w ]*\\w|\\s\\W+|\\W+|\\n'\n","    return re.findall(pattern, text)\n","\n","\n","def encoder_data(text, maxlen=MAXLEN):\n","    text = \"\\x00\" + text\n","    x = np.zeros((maxlen, len(alphabet)))\n","    for i, c in enumerate(text[:maxlen]):\n","        x[i, alphabet.index(c)] = 1\n","    if i < maxlen - 1:\n","        for j in range(i + 1, maxlen):\n","            x[j, 0] = 1\n","    return x\n","\n","\n","def decoder_data(x):\n","    x = x.argmax(axis=-1)\n","    return ''.join(alphabet[i] for i in x)\n","\n","\n","def nltk_ngrams(words, n=5):\n","    return ngrams(words.split(), n)\n","\n","\n","def guess(ngram):\n","    # Example: ngram = ('Tôi', 'ddi', 'học', 'ở', 'đâu')\n","    text = ' '.join(ngram)\n","    preds = model.predict(np.array([encoder_data(text)]), verbose=0)\n","    return decoder_data(preds[0]).strip('\\x00')\n","\n","\n","def correct(sentence):\n","    # Lặp qua từng ký tự trong câu.\n","    for i in sentence:\n","        # Kiểm tra xem ký tự hiện tại có trong danh sách các ký tự được chấp nhận hay không.\n","        # Nếu không, thay thế ký tự đó bằng khoảng trắng.\n","        if i not in accepted_char:\n","            sentence = sentence.replace(i, \" \")\n","    # Kiểm tra số từ trong câu\n","    num_words = len(sentence.split())\n","\n","    # Nếu số từ không đủ để tạo n-gram, trả về câu không đổi\n","    if num_words < NGRAM:\n","      ngrams = list(nltk_ngrams(sentence, n=num_words))\n","      # Đoán các từ trong các n-gram.\n","      guessed_ngrams = list(guess(ngram) for ngram in ngrams)\n","      # Tạo một danh sách các bảng ứng viên từ.\n","      candidates = [Counter() for _ in range(len(guessed_ngrams) + num_words - 1)]\n","\n","      # Lặp qua các n-gram đã đoán.\n","      for nid, ngram in (enumerate(guessed_ngrams)):\n","          # Tách các từ từ n-gram.\n","          for wid, word in (enumerate(re.split(' +', ngram))):\n","              # Cập nhật bảng ứng viên từ với từ hiện tại.\n","              candidates[nid + wid].update([word])\n","      # Xây dựng câu đúng bằng cách chọn từ phổ biến nhất từ mỗi bảng ứng viên từ.\n","      output = ' '.join(c.most_common(1)[0][0] for c in candidates)\n","    else:\n","      # Tạo các n-gram từ câu đã được xử lý.\n","      ngrams = list(nltk_ngrams(sentence, n=NGRAM))\n","      # Đoán các từ trong các n-gram.\n","      guessed_ngrams = list(guess(ngram) for ngram in ngrams)\n","      # Tạo một danh sách các bảng ứng viên từ.\n","      candidates = [Counter() for _ in range(len(guessed_ngrams) + NGRAM - 1)]\n","\n","      # Lặp qua các n-gram đã đoán.\n","      for nid, ngram in (enumerate(guessed_ngrams)):\n","          # Tách các từ từ n-gram.\n","          for wid, word in (enumerate(re.split(' +', ngram))):\n","              # Cập nhật bảng ứng viên từ với từ hiện tại.\n","              candidates[nid + wid].update([word])\n","      # Xây dựng câu đúng bằng cách chọn từ phổ biến nhất từ mỗi bảng ứng viên từ.\n","      output = ' '.join(c.most_common(1)[0][0] for c in candidates)\n","    return output\n","\n","def check_text(regex, text):\n","    pattern = re.compile(regex)\n","    if pattern.fullmatch(text):\n","        return True\n","    else:\n","        return False\n","def correct_2(text):\n","  ep = extract_phrases(text)\n","  rs_ = \"\"\n","  for value in ep:\n","    regex = r'\\w[\\w ]+'\n","    if check_text(regex, value):\n","      rs_ = rs_ + correct(value)\n","    else:\n","      rs_ = rs_ + value\n","  return rs_"],"metadata":{"id":"3EMrxCzWA-JK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["raw_text = \"Bất cuws lúc nao, trong cuộc phieeu lưu đơn thương độc max\"\n","results = correct(raw_text)\n","results"],"metadata":{"id":"-_fBwVASBVHk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text= \"Bất cuws lúc nao, trong cuộc phieeu lưu đơn thương độc max. Tôi ddi học ở đaau. Cơn mưa ngang qua,  cơn muwa  @ ngang qua\\nBất cuws lúc nao, trong cuộc phieeu lưu đơn thương độc max. Tôi ddi học ở đaau. Cơn mưa ngang qua,  cơn muwa  @ ngang qua\"\n","results = correct_2(text)\n","results"],"metadata":{"id":"lGHZFkAudtAA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import re\n","\n","# Chuỗi có nhiều dòng\n","chuoi = \"\"\"Dòng đầu tiên\n","Dòng thứ hai\n","Dòng thứ ba\"\"\"\n","\n","# Sử dụng re.split để tách chuỗi dựa trên ký tự xuống dòng\n","ket_qua = re.split(\"\\n\", chuoi)\n","\n","print(ket_qua)  # Kết quả: ['Dòng đầu tiên', 'Dòng thứ hai', 'Dòng thứ ba']"],"metadata":{"id":"rfY3PZWjOp9l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["extract_phrases(text)"],"metadata":{"id":"QtOfmSqJjCV1"},"execution_count":null,"outputs":[]}]}